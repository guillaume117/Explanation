{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How good is your Explanation\n",
    "### Algorithmic Stability Measures to Assess the Quality of Explanations for Deep Neural Networks\n",
    "NoteBook Deep Learning Guillaume BERTHELOT\n",
    "\n",
    "\n",
    "This notebook is freely inspired by the article [\"How good is Your Explanation\"](https://openaccess.thecvf.com/content/WACV2022/html/Fel_How_Good_Is_Your_Explanation_Algorithmic_Stability_Measures_To_Assess_WACV_2022_paper.html)\n",
    "\n",
    "[1] Fel, Thomas and Vigouroux, David and Cadène, Rémi and Serre, Thomas, \"How Good Is Your Explanation? Algorithmic Stability Measures To Assess the Quality of Explanations for Deep Neural Networks\" Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Année.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction \n",
    "\n",
    "The explanability of machine learning algorithms is a fundamental challenge. While these algorithms are now used in an increasing number of domains, the inherent black-box nature of neural networks makes them challenging to deploy in applications where security is a concern. Research on the explanability of neural networks is highly active today. In this notebook, we will explore a proposed method that allows the evaluation of the relevance of an explanability method for a neural network used for image labeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerous explainability methods have been introduced to assess the quality of a neural network. The problem is that each of these explainability methods may harbor biases, especially confirmation bias. Without proper evaluation of these methods themselves, they cannot ensure the quality of a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, the method employed by Fel et al. to assess the quality of explainability in decision-making by a convolutional neural network is to observe how robust it is to changes during the training process of a neural network. A good explainability should ideally consistently point to the same regions of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<b>The issue is therefore formulated as follows: among a set of CNN models and a set of explainability methods, evaluate, for each pair (CNN, method), the robustness of the explainability.</b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each pair (CNN model, explainability method), evaluating the explainability method involves testing its robustness when modifying the training sets of the neural network. An expected outcome for a good explainability method would be that, for two inferences on the same image formulated by two sets of parameters of the same neural network, the areas that contributed the most to the inferences are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <figure>\n",
    "        <img src=\"./figures/Explain.png\" alt=\"Eplain\" width = \"500\" height=\"300\">\n",
    "        <figcaption>Principle of measuring algorithmic stability proposed by [1].</figcaption>\n",
    "    </figure>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two sets of parameters are derived from training performed with slightly modified data. One way to achieve this is by taking a training dataset and extracting multiple training datasets with some of the data removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "At this point in the reading, it is useful to recall the work done in the [\"Explainability\"](https://github.com/SupaeroDataScience/machine-learning/blob/main/14%20-%20Explainability/Notebook_explainability_students_version.ipynb) notebook.\n",
    "\n",
    "Indeed, even though we won't be using the same libraries here, it is helpful to recall the principle of explanation zone detection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a good explanation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's introduce three characteristics that a good explainability should possess. \n",
    "\n",
    "Fidelity: The metric evaluating an explanation should reflect the internal decision-making process. \n",
    "\n",
    "Generalizability, denoted as MeGe: a good explanation should point to identical evidence. \n",
    "\n",
    "Lastly, relative consistency, denoted as ReCo: when an image is misclassified, the explanation should point to different areas than those used for a correct explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "We are beginning to understand that assessing the quality of an explainability method can be computationally expensive. Through this notebook, I propose to evaluate a method called GRAD-CAM applied to three networks: ResNet 18 and VGG19, trained different datasets, such as MNIST, FashionMNIST or CIFAR10. The provided code can be executed on CUDA or Apple silicon (MPS). If desired, you can retrain the models, which may take some time. The parameters are saved in files, allowing you to quickly replay the quality assessment part without retraining the models.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad-CAM (CG) Method for explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, our concern will be focused on the GRAD-CAM (CG) Method. The Grad-CAM (Gradient-weighted Class Activation Mapping) method is an interpretability technique for neural networks that generates visual explanations by highlighting the regions of an input image that contribute most to the network's decision. It achieves this by leveraging the gradient information flowing into the final convolutional layer to emphasize class-discriminative regions.\n",
    "\n",
    "\n",
    "For obtaining the map of features activations, we need to compute the weights $\\alpha_c^{(k)}$ associated to each of the feature of the map activation \n",
    "\n",
    "$$\\Phi_{GC} = \\max(0, \\sum_i \\sum_j \\frac{\\partial f_c(x)}{\\partial A_{ij}^{(k)}} \\cdot \\alpha^{(k)}_c A_{ij}^{(k)}) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to implement a grad cam on a common neural network and let see what happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We firstly start to download a pretrained VGG to obtain it weights, then we will upload this weights on a custom VGG implemented with what we will call a hook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>You can first try to open the CNN.VGG class and try to see where I've inserted the Hook !</b>\n",
    "</div class>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you run it on colab:\n",
    "!git clone https://github.com/guillaume117/Explanation.git\n",
    "%cd Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torchvision.models import vgg19\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split, WeightedRandomSampler,DataLoader\n",
    "from util.addGitignore import addGitignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we download the pretrained version of VGG19 and then we save its weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = vgg19(pretrained =True)\n",
    "addGitignore('CNN/VGG19_Pretrained.pth' )\n",
    "#torch.save(model.state_dict(),'./CNN/VGG19_Pretrained.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we call our custom VGG! If it is well designed, the weights should perfectly fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN.VGG import VGG\n",
    "model=VGG(num_classes=1000,hooked=True,num_depth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./CNN/VGG19_Pretrained.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isn't it magic!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see if intuitively the mapping of explanation is in accordance with what we thought would be relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision.io import read_image\n",
    "\n",
    "img= read_image('images/H160.png')\n",
    "\n",
    "img = img.unsqueeze(0)\n",
    "img.size()\n",
    "model.eval()\n",
    "img = img[:,1:4,:,:].float()\n",
    "pred = model(img)\n",
    "P=pred.argmax()\n",
    "P=int(P)\n",
    "pred[:,P].backward()\n",
    "gradients = model.get_activations_gradient()\n",
    "pooled_gradients = torch.mean(gradients, dim=[2,3])\n",
    "activations = model.get_activations().detach()\n",
    "activations.size()\n",
    "pooled_gradients.size()\n",
    "for i in range(512):\n",
    "    activations[ :,i, :, :] *= pooled_gradients[:,i]\n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "heatmap /= torch.max(heatmap)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# draw the heatmap\n",
    "plt.matshow(heatmap.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('./images/H160.png')\n",
    "heatmap = np.array(heatmap)\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.3 + img\n",
    "superimposed_img_8bit = cv2.convertScaleAbs(superimposed_img)\n",
    "cv2.imwrite('./images/map.jpg', superimposed_img)\n",
    "plt.imshow(cv2.cvtColor(superimposed_img_8bit, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok this seems to be relevant, the mapping is concentraded over the beak, feathers and twig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "\n",
    "\n",
    "<b>This was an easy stuff, no? Let's go further and try to improve our assessment over the quality of explanation. </b>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wan't to go further, we firsly need to have a good metrics. As proposed in the paper, I 've chosen a sperman correlation in order to evaluate the difference between to mapping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $k$ -Fold Cross-Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explain the algorithm: the idea is to generate 10 different training subsets. For each of these subsets, we will conduct training. For each of the networks, we will map the heatmap with inferences for 1000 samples. Consequently, for each of the 10 networks, we will have heatmaps for the 1000 samples. We can then check whether the heatmaps are similar based on whether the sample was used for training or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance metric\n",
    "In the first step, we need a metric to measure the distance between the heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from util.functions import generate_images \n",
    "from util.functions import spearman_image_correlation\n",
    "from util.functions import divergence_KL_1\n",
    "from util.functions import spearman_noise_correlation\n",
    "\n",
    "\n",
    "\n",
    "dist =np.arange(10,50,8)\n",
    "fig, axes = plt.subplots(1, 5, figsize=(30, 3))\n",
    "\n",
    "for i in range(5):\n",
    "    axes[i].imshow(generate_images(x=dist[i],y=dist[i]), cmap='viridis')\n",
    "    axes[i].axis('off') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_origin = generate_images(x=10,y=10,noisy=False)\n",
    "dist = 10\n",
    "\n",
    "measure_assemnent = [(spearman_image_correlation(image_origin,generate_images(x=dist,y=dist,noisy=False)))for dist  in np.arange(10,50,1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if this metric seems to measure distance. One would expect the distance to improve as the points get farther apart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(10,50,1),measure_assemnent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok it seems to be ok. If you want to play, I've added some noise and I would be pleased to speak with you about your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Splitting and learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time to roll up our sleeves. We are going to build the following algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <figure>\n",
    "        <img src=\"./figures/algo.png\" alt=\"algo\" width = \"600\" height=\"800\">\n",
    "        <figcaption>Training procedure [1].</figcaption>\n",
    "    </figure>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On this next cell, some classes have been built to generate k = num_subset sub-datasets from a standard dataset, each composed of 'sparsity*100' percent of the original dataset. Note that all the sub-datasets maintain the same class proportions as the original one. You can take a look at the GenerateDataset class to see the implementation. As it is essential to retrieve the indices of each sub-dataset, they are recorded and will be processed next. Once our sub-datasets are computed, it's time to train each dataset using the ResName neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose betwen for ResName:\n",
    "\n",
    "A simple CNN : SimpleCNN \n",
    "Resnet18 \n",
    "VGG\n",
    "and VGG_Cifar (the difference is here because Cifar10 is a colored dataset)\n",
    "\n",
    "And betwen MNINST, FashionMNIST, or CIFAR10 (exclusively with VGG_Cifar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class ='alert alert-info>\n",
    "Our benchmark neural network will be a simple network corresponding to the following graph. This will allow for quick training for the purposes of the exercise\n",
    "</div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class ='alert alert-info'>\n",
    "For the purpose of this exercice, our benchmark neural network will be a simple network corresponding to the following graph.\n",
    " This will allow for quick training for the purposes of the exercise\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <figure>\n",
    "        <img src=\"./figures/SimpleCNN.png\" alt=\"SimpleCNN\" width = \"700\" height=\"800\">\n",
    "        <figcaption>SimpleCNN.</figcaption>\n",
    "    </figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's execute the first part of the algorithm, which involves generating the dataset, training on each dataset, and measuring explainability for 1000 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <figure>\n",
    "        <img src=\"./figures/algo_step1.png\" alt=\"Eplain\" width = \"500\" height=\"300\">\n",
    "        <figcaption>Generation, training and explain [1].</figcaption>\n",
    "    </figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 9.78 µs\n",
      "CIFAR_10_VGG already logged in .gitignore\n",
      "./CIFAR_10_VGG\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT\n",
      "Training of subset n 0 over 10 on VGG_Cifar\n",
      "TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 2.2756 Acc: 0.1445\n",
      "val Loss: 2.2542 Acc: 0.1943\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m NotebookCase\u001b[38;5;241m.\u001b[39madd_network_type(ResName\u001b[38;5;241m=\u001b[39mResName)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#NotebookCase.generate()\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mNotebookCase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_sub_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mResName\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHeatmap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComputeHeatmap\n\u001b[1;32m     26\u001b[0m num_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "File \u001b[0;32m~/SDD/NotebookHowGoodIsYourExplanation/util/GenerateAndTrain.py:275\u001b[0m, in \u001b[0;36mGenerateDataset.train_sub_dataset\u001b[0;34m(self, ResName, num_epoch, batch_size, learning_rate, scheduler)\u001b[0m\n\u001b[1;32m    269\u001b[0m         criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m    274\u001b[0m         train\u001b[38;5;241m=\u001b[39mTrainDataset(model, criterion, optimizer, scheduler,num_epoch,learning_rate,batch_size,device \u001b[38;5;241m=\u001b[39m device)\n\u001b[0;32m--> 275\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mResName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Trained_dataset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mResName \u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSimpleCNN\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/SDD/NotebookHowGoodIsYourExplanation/TRAIN/train.py:78\u001b[0m, in \u001b[0;36mTrainDataset.train_model\u001b[0;34m(self, train_dataset, val_dataset)\u001b[0m\n\u001b[1;32m     76\u001b[0m             loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 78\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     79\u001b[0m     running_corrects \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(preds \u001b[38;5;241m==\u001b[39m labels\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m     80\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m dataset_sizes[phase]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time\n",
    "num_subset = 10\n",
    "name_dataset = 'CIFAR10'\n",
    "name_folder = 'CIFAR_10_VGG'\n",
    "sparsity = 0.8\n",
    "image_size = 56\n",
    "ResName = 'VGG_Cifar'\n",
    "num_epoch=10\n",
    "batch_size=512\n",
    "learning_rate=0.01\n",
    "import time\n",
    "\n",
    "\n",
    "from util.GenerateAndTrain import GenerateDataset\n",
    "from util.generate_indice_global import generate_indice_global\n",
    "\n",
    "\n",
    "\n",
    "NotebookCase=GenerateDataset(num_subset=num_subset, name_dataset=name_dataset, name_folder=name_folder,image_size=image_size,sparsity=sparsity)\n",
    "NotebookCase.add_network_type(ResName=ResName)\n",
    "#NotebookCase.generate()\n",
    "NotebookCase.train_sub_dataset(ResName,num_epoch=num_epoch,batch_size=batch_size,learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "from util.Heatmap import ComputeHeatmap\n",
    "num_sample = 1000\n",
    "test = ComputeHeatmap(NotebookCase,num_sample)\n",
    "test.compute_heatmap()\n",
    "heatmap_global = test.get_heatmap()\n",
    "pred_acc = test.get_pred_acc()\n",
    "indices_global,printed_list = generate_indice_global( NotebookCase, num_sample)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which sample has been chosen ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printed_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I propose that you take a look at all the classes that have been written. Now, we are at the second stage of the algorithm, It was a little bit tricky\n",
    "\n",
    "And now, let's make this a bit more visually appealing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'>\n",
    "So, we created 10 sub-datasets, trained them, and generated heatmaps for each of the first 1000 samples. Can we now visualize an example of the heatmap generated for a sample? You will see in the following figure the 10 inferences made by the 10 sub-datasets for the same sample\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "sample=78\n",
    "fig, axes = plt.subplots(1, 10, figsize=(30, 3))\n",
    "train_dataset = torch.load(f'{name_folder}/{name_dataset}_dataset_global.pt')\n",
    "img=torch.tensor(train_dataset[sample][0])\n",
    "\n",
    "img = img[0,:,:]\n",
    "\n",
    "for i in range(10):\n",
    "    heatmap = heatmap_global[i][sample].squeeze()\n",
    "     #heatmap = np.uint8(255*heatmap)\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    superimposed_img = 0.05*img+0.5*heatmap\n",
    "    axes[i].imshow(superimposed_img,cmap = 'viridis')\n",
    "    axes[i].axis('off') \n",
    "    \n",
    "    if indices_global[sample,i]==1:\n",
    "          rect = patches.Rectangle((0, 0), image_size-1, image_size-1, linewidth=5, edgecolor='#39FF14', facecolor='none')\n",
    "          axes[i].add_patch(rect)\n",
    "          axes[i].set_title(f'Indice {sample} was trained \\n on network{i} ')\n",
    "    else :\n",
    "          axes[i].set_title(f'Indice {sample} was not trained \\n on network{i} ')\n",
    "          rect = patches.Rectangle((0, 0), 27, 27, linewidth=5, edgecolor='yellow', facecolor='none')\n",
    "          axes[i].add_patch(rect)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $S^=$ and $S^{\\neq}$\n",
    "We define S-equal as the set of elements that received correct labels, and S-diff as the set of elements that received both correct and incorrect inferences. We expect, for good explainability, that the distances for S-equal are lower than for S-diff.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's compute $S^=$ and $S^{\\neq}$\n",
    "\n",
    "We define S-equal as the set of elements that received correct labels, and S-diff as the set of elements that received both correct and incorrect inferences. We expect, for good explainability, that the distances for S-equal are lower than for S-diff.\"\n",
    "Here after you'll find the second parts of the algorithm : \n",
    "\n",
    "<center>\n",
    "    <figure>\n",
    "        <img src=\"./figures/algo_step_2.png\" alt=\"Eplain\" width = \"500\" height=\"400\">\n",
    "        <figcaption>Computing S equal and S diff[1].</figcaption>\n",
    "    </figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we use our metric, the spearman correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from util.functions import spearman_image_correlation\n",
    "S_equal =[]\n",
    "S_diff =[]\n",
    "for i in range(num_subset):\n",
    "    for p in range(num_sample):\n",
    "        if indices_global[p,i]==0:\n",
    "            phi_i_x = heatmap_global[i][p]\n",
    "            pred_i = int(pred_acc[p,i])\n",
    "            for j in range(num_subset):\n",
    "                if i==j :\n",
    "                    pass\n",
    "                else :\n",
    "                    if indices_global[i,j]==1:\n",
    "\n",
    "                        phi_j_x = heatmap_global[j][p]\n",
    "                        pred_j = int(pred_acc[p,j])\n",
    "                        spear_coor = spearman_image_correlation(phi_i_x,phi_j_x)\n",
    "                        if (pred_i==1 & pred_j==1):\n",
    "                            S_equal.append(spear_coor)\n",
    "                        elif (pred_i==1 ^ pred_j==1): \n",
    "                            S_diff.append(spear_coor)\n",
    "                        else :\n",
    "                            pass\n",
    "\n",
    "\n",
    "                        \n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now calculate the two metrics for which we've just done all this work, MeGe and ReCo. For each of these metrics, ranging from 0 to 1, the optimal performance is achieved when they are close to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ MeGe = \\left(1 + \\frac{1}{\\lvert S^= \\rvert} \\sum_{\\delta \\in S^=} \\delta \\right)^{-1} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ReCo = \\max_{\\gamma \\in S} TPR(\\gamma)+TNR(\\gamma)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MeGe stands for Generalizability: a good explanation should point to identical evidence. \n",
    "\n",
    "Reco : relative consistency, denoted as ReCo: when an image is misclassified, the explanation should point to different areas than those used for a correct explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "S=S_equal+S_diff\n",
    "\n",
    "\n",
    "def calculate_TPR_plus_TNR_minus_1(S,S_equal,S_diff,gamma):\n",
    "    \n",
    "    \n",
    "\n",
    "    num_tpr = len([delta for delta in S_equal if delta <= gamma])\n",
    "    denom_tpr = len([delta for delta in S if delta <= gamma])\n",
    "    num_tnr = len([delta for delta in S_diff if delta > gamma])\n",
    "    denom_tnr = len([delta for delta in S if delta > gamma])\n",
    "    if (denom_tpr==0 or denom_tnr==0):\n",
    "        return -np.inf\n",
    "    else :\n",
    "        return num_tpr/denom_tpr+num_tnr/denom_tnr-1\n",
    "\n",
    "ReCo = np.max([calculate_TPR_plus_TNR_minus_1(S,S_equal,S_diff,gamma) for gamma in S])\n",
    "\n",
    "MeGe = 1/(1+(1/len(S_equal))*np.sum(S_equal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MeGe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now observe the distribution of S_equal and S_diff. A good explicability will have a strong density of S_equal for low distance values and a density of S_diff centered around high distance values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see the result obtained in the paper for a case :{ GradCAM, ResNet18, CIFAR10}\n",
    "<center>\n",
    "    <figure>\n",
    "        <img src=\"./figures/result.png\" alt=\"Eplain\" width = \"500\" height=\"300\">\n",
    "        <figcaption>Distance mapping for GradCAM over ResNet18 with CIFAR10 [1].</figcaption>\n",
    "    </figure>\n",
    "</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(S_equal, bins=50, alpha=0.7, label='S_equal', color='blue', density=True)\n",
    "plt.hist(S_diff, bins=100, alpha=0.7, label='S_diff', color='orange', density=True)\n",
    "plt.x_axis=('Distance')\n",
    "plt.title('Distance between explanation')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class ='alert alert-success'>\n",
    "In conclusion, we can see that our simple network used to train FashionMNIST exhibits good explainability. Indeed, the values of ReCo and MeGe are favorable, and furthermore, we observe a clear separability of the densities for S-equal and S-diff. You can now test other datasets on different neural networks\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class ='alert alert-info'>\n",
    "We have obtained initial results for evaluating the interpretability method applied to my simple neural network. You can apply it to other cases (VGG, ResNet) and other datasets (MNIST, CIFAR10). One noticeable observation is the relative instability of this method. Indeed, I have never obtained identical results for two different runs. This is likely linked to the size of the evaluated sample (1000), which represents only 1/60 of the entire dataset. It's possible to try running the algorithm on the entire dataset, but the computation time is long (num_sample = 60000). However, the primary cause of instability is likely the limited number of sub-datasets and training instances. We conducted 10 trainings, and it may be necessary to increase this number, albeit at the expense of higher computational and memory costs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
