{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How good is your Explanation\n",
    "### Algorithmic Stability Measures to Assess the Quality of Explanations for Deep Neural Networks\n",
    "NoteBook Deep Learning Guillaume BERTHELOT\n",
    "\n",
    "\n",
    "This notebook is freely inspired by the article [\"How good is Your Explanation\"](https://openaccess.thecvf.com/content/WACV2022/html/Fel_How_Good_Is_Your_Explanation_Algorithmic_Stability_Measures_To_Assess_WACV_2022_paper.html)\n",
    "\n",
    "[1] Fel, Thomas and Vigouroux, David and Cadène, Rémi and Serre, Thomas, \"How Good Is Your Explanation? Algorithmic Stability Measures To Assess the Quality of Explanations for Deep Neural Networks\" Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Année.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction \n",
    "\n",
    "The explainability of machine learning algorithms is a fundamental challenge. While these algorithms are now used in an increasing number of domains, the inherent black-box nature of neural networks makes them challenging to deploy in applications where security is a concern. Research on the explainability of neural networks is highly active today. In this notebook, we will explore a proposed method that allows the evaluation of the relevance of decision-making in a neural network used for image labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, the method employed by Fel et al. to assess the quality of explainability in decision-making by a convolutional neural network is to observe how robust it is to changes during the training process. A good explainability should ideally consistently point to the same regions of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    At this point in the reading, it is useful to recall the work done in the [\"Explainability\"](https://github.com/SupaeroDataScience/machine-learning/blob/main/14%20-%20Explainability/Notebook_explainability_students_version.ipynb) notebook.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
